{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Implement Your Machine Learning Project Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will implement the machine learning project plan you created in the written assignment. You will:\n",
    "\n",
    "1. Load your data set and save it to a Pandas DataFrame.\n",
    "2. Perform exploratory data analysis on your data to determine which feature engineering and data preparation techniques you will use.\n",
    "3. Prepare your data for your model and create features and a label.\n",
    "4. Fit your model to the training data and evaluate your model.\n",
    "5. Improve your model by performing model selection and/or feature selection techniques to find best model for your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "\n",
    "Before you get started, import a few packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load the Data Set\n",
    "\n",
    "\n",
    "You have chosen to work with one of four data sets. The data sets are located in a folder named \"data.\" The file names of the three data sets are as follows:\n",
    "\n",
    "* The \"adult\" data set that contains Census information from 1994 is located in file `adultData.csv`\n",
    "* The airbnb NYC \"listings\" data set is located in file  `airbnbListingsData.csv`\n",
    "* The World Happiness Report (WHR) data set is located in file `WHR2018Chapter2OnlineData.csv`\n",
    "* The book review data set is located in file `bookReviewsData.csv`\n",
    "\n",
    "\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load your data using `pd.read_csv()` and save it to DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>Life Ladder</th>\n",
       "      <th>Log GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy at birth</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>Positive affect</th>\n",
       "      <th>Negative affect</th>\n",
       "      <th>Confidence in national government</th>\n",
       "      <th>Democratic Quality</th>\n",
       "      <th>Delivery Quality</th>\n",
       "      <th>Standard deviation of ladder by country-year</th>\n",
       "      <th>Standard deviation/Mean of ladder by country-year</th>\n",
       "      <th>GINI index (World Bank estimate)</th>\n",
       "      <th>GINI index (World Bank estimate), average 2000-15</th>\n",
       "      <th>gini of household income reported in Gallup, by wp5-year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2008</td>\n",
       "      <td>3.723590</td>\n",
       "      <td>7.168690</td>\n",
       "      <td>0.450662</td>\n",
       "      <td>49.209663</td>\n",
       "      <td>0.718114</td>\n",
       "      <td>0.181819</td>\n",
       "      <td>0.881686</td>\n",
       "      <td>0.517637</td>\n",
       "      <td>0.258195</td>\n",
       "      <td>0.612072</td>\n",
       "      <td>-1.929690</td>\n",
       "      <td>-1.655084</td>\n",
       "      <td>1.774662</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2009</td>\n",
       "      <td>4.401778</td>\n",
       "      <td>7.333790</td>\n",
       "      <td>0.552308</td>\n",
       "      <td>49.624432</td>\n",
       "      <td>0.678896</td>\n",
       "      <td>0.203614</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>0.583926</td>\n",
       "      <td>0.237092</td>\n",
       "      <td>0.611545</td>\n",
       "      <td>-2.044093</td>\n",
       "      <td>-1.635025</td>\n",
       "      <td>1.722688</td>\n",
       "      <td>0.391362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.441906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.758381</td>\n",
       "      <td>7.386629</td>\n",
       "      <td>0.539075</td>\n",
       "      <td>50.008961</td>\n",
       "      <td>0.600127</td>\n",
       "      <td>0.137630</td>\n",
       "      <td>0.706766</td>\n",
       "      <td>0.618265</td>\n",
       "      <td>0.275324</td>\n",
       "      <td>0.299357</td>\n",
       "      <td>-1.991810</td>\n",
       "      <td>-1.617176</td>\n",
       "      <td>1.878622</td>\n",
       "      <td>0.394803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.327318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.831719</td>\n",
       "      <td>7.415019</td>\n",
       "      <td>0.521104</td>\n",
       "      <td>50.367298</td>\n",
       "      <td>0.495901</td>\n",
       "      <td>0.175329</td>\n",
       "      <td>0.731109</td>\n",
       "      <td>0.611387</td>\n",
       "      <td>0.267175</td>\n",
       "      <td>0.307386</td>\n",
       "      <td>-1.919018</td>\n",
       "      <td>-1.616221</td>\n",
       "      <td>1.785360</td>\n",
       "      <td>0.465942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.336764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.782938</td>\n",
       "      <td>7.517126</td>\n",
       "      <td>0.520637</td>\n",
       "      <td>50.709263</td>\n",
       "      <td>0.530935</td>\n",
       "      <td>0.247159</td>\n",
       "      <td>0.775620</td>\n",
       "      <td>0.710385</td>\n",
       "      <td>0.267919</td>\n",
       "      <td>0.435440</td>\n",
       "      <td>-1.842996</td>\n",
       "      <td>-1.404078</td>\n",
       "      <td>1.798283</td>\n",
       "      <td>0.475367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  year  Life Ladder  Log GDP per capita  Social support  \\\n",
       "0  Afghanistan  2008     3.723590            7.168690        0.450662   \n",
       "1  Afghanistan  2009     4.401778            7.333790        0.552308   \n",
       "2  Afghanistan  2010     4.758381            7.386629        0.539075   \n",
       "3  Afghanistan  2011     3.831719            7.415019        0.521104   \n",
       "4  Afghanistan  2012     3.782938            7.517126        0.520637   \n",
       "\n",
       "   Healthy life expectancy at birth  Freedom to make life choices  Generosity  \\\n",
       "0                         49.209663                      0.718114    0.181819   \n",
       "1                         49.624432                      0.678896    0.203614   \n",
       "2                         50.008961                      0.600127    0.137630   \n",
       "3                         50.367298                      0.495901    0.175329   \n",
       "4                         50.709263                      0.530935    0.247159   \n",
       "\n",
       "   Perceptions of corruption  Positive affect  Negative affect  \\\n",
       "0                   0.881686         0.517637         0.258195   \n",
       "1                   0.850035         0.583926         0.237092   \n",
       "2                   0.706766         0.618265         0.275324   \n",
       "3                   0.731109         0.611387         0.267175   \n",
       "4                   0.775620         0.710385         0.267919   \n",
       "\n",
       "   Confidence in national government  Democratic Quality  Delivery Quality  \\\n",
       "0                           0.612072           -1.929690         -1.655084   \n",
       "1                           0.611545           -2.044093         -1.635025   \n",
       "2                           0.299357           -1.991810         -1.617176   \n",
       "3                           0.307386           -1.919018         -1.616221   \n",
       "4                           0.435440           -1.842996         -1.404078   \n",
       "\n",
       "   Standard deviation of ladder by country-year  \\\n",
       "0                                      1.774662   \n",
       "1                                      1.722688   \n",
       "2                                      1.878622   \n",
       "3                                      1.785360   \n",
       "4                                      1.798283   \n",
       "\n",
       "   Standard deviation/Mean of ladder by country-year  \\\n",
       "0                                           0.476600   \n",
       "1                                           0.391362   \n",
       "2                                           0.394803   \n",
       "3                                           0.465942   \n",
       "4                                           0.475367   \n",
       "\n",
       "   GINI index (World Bank estimate)  \\\n",
       "0                               NaN   \n",
       "1                               NaN   \n",
       "2                               NaN   \n",
       "3                               NaN   \n",
       "4                               NaN   \n",
       "\n",
       "   GINI index (World Bank estimate), average 2000-15  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "   gini of household income reported in Gallup, by wp5-year  \n",
       "0                                                NaN         \n",
       "1                                           0.441906         \n",
       "2                                           0.327318         \n",
       "3                                           0.336764         \n",
       "4                                           0.344540         "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "WHRDataSet_filename = os.path.join(os.getcwd(), \"data\", \"WHR2018Chapter2OnlineData.csv\")\n",
    "df = pd.read_csv(WHRDataSet_filename, header=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis\n",
    "\n",
    "The next step is to inspect and analyze your data set with your machine learning problem and project plan in mind. \n",
    "\n",
    "This step will help you determine data preparation and feature engineering techniques you will need to apply to your data to build a balanced modeling data set for your problem and model. These data preparation techniques may include:\n",
    "* addressing missingness, such as replacing missing values with means\n",
    "* renaming features and labels\n",
    "* finding and replacing outliers\n",
    "* performing winsorization if needed\n",
    "* performing one-hot encoding on categorical features\n",
    "* performing vectorization for an NLP problem\n",
    "* addressing class imbalance in your data sample to promote fair AI\n",
    "\n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. \n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Life Ladder</th>\n",
       "      <th>Log GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy at birth</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>Positive affect</th>\n",
       "      <th>Negative affect</th>\n",
       "      <th>Confidence in national government</th>\n",
       "      <th>Democratic Quality</th>\n",
       "      <th>Delivery Quality</th>\n",
       "      <th>Standard deviation of ladder by country-year</th>\n",
       "      <th>Standard deviation/Mean of ladder by country-year</th>\n",
       "      <th>GINI index (World Bank estimate)</th>\n",
       "      <th>GINI index (World Bank estimate), average 2000-15</th>\n",
       "      <th>gini of household income reported in Gallup, by wp5-year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1535.000000</td>\n",
       "      <td>1549.000000</td>\n",
       "      <td>1553.000000</td>\n",
       "      <td>1533.000000</td>\n",
       "      <td>1482.000000</td>\n",
       "      <td>1472.000000</td>\n",
       "      <td>1544.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1401.000000</td>\n",
       "      <td>1391.000000</td>\n",
       "      <td>1391.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>1386.000000</td>\n",
       "      <td>1205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2011.820743</td>\n",
       "      <td>5.433676</td>\n",
       "      <td>9.220822</td>\n",
       "      <td>0.810669</td>\n",
       "      <td>62.249887</td>\n",
       "      <td>0.728975</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.753622</td>\n",
       "      <td>0.708969</td>\n",
       "      <td>0.263171</td>\n",
       "      <td>0.480207</td>\n",
       "      <td>-0.126617</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>2.003501</td>\n",
       "      <td>0.387271</td>\n",
       "      <td>0.372846</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.445204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.419787</td>\n",
       "      <td>1.121017</td>\n",
       "      <td>1.184035</td>\n",
       "      <td>0.119370</td>\n",
       "      <td>7.960671</td>\n",
       "      <td>0.145408</td>\n",
       "      <td>0.164202</td>\n",
       "      <td>0.185538</td>\n",
       "      <td>0.107644</td>\n",
       "      <td>0.084006</td>\n",
       "      <td>0.190724</td>\n",
       "      <td>0.873259</td>\n",
       "      <td>0.981052</td>\n",
       "      <td>0.379684</td>\n",
       "      <td>0.119007</td>\n",
       "      <td>0.086609</td>\n",
       "      <td>0.083694</td>\n",
       "      <td>0.105410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2005.000000</td>\n",
       "      <td>2.661718</td>\n",
       "      <td>6.377396</td>\n",
       "      <td>0.290184</td>\n",
       "      <td>37.766476</td>\n",
       "      <td>0.257534</td>\n",
       "      <td>-0.322952</td>\n",
       "      <td>0.035198</td>\n",
       "      <td>0.362498</td>\n",
       "      <td>0.083426</td>\n",
       "      <td>0.068769</td>\n",
       "      <td>-2.448228</td>\n",
       "      <td>-2.144974</td>\n",
       "      <td>0.863034</td>\n",
       "      <td>0.133908</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>0.228833</td>\n",
       "      <td>0.223470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2009.000000</td>\n",
       "      <td>4.606351</td>\n",
       "      <td>8.310665</td>\n",
       "      <td>0.748304</td>\n",
       "      <td>57.299580</td>\n",
       "      <td>0.633754</td>\n",
       "      <td>-0.114313</td>\n",
       "      <td>0.697359</td>\n",
       "      <td>0.621471</td>\n",
       "      <td>0.204116</td>\n",
       "      <td>0.334732</td>\n",
       "      <td>-0.772010</td>\n",
       "      <td>-0.717463</td>\n",
       "      <td>1.737934</td>\n",
       "      <td>0.309722</td>\n",
       "      <td>0.307000</td>\n",
       "      <td>0.321583</td>\n",
       "      <td>0.368531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2012.000000</td>\n",
       "      <td>5.332600</td>\n",
       "      <td>9.398610</td>\n",
       "      <td>0.833047</td>\n",
       "      <td>63.803192</td>\n",
       "      <td>0.748014</td>\n",
       "      <td>-0.022638</td>\n",
       "      <td>0.808115</td>\n",
       "      <td>0.717398</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>0.463137</td>\n",
       "      <td>-0.225939</td>\n",
       "      <td>-0.210142</td>\n",
       "      <td>1.960345</td>\n",
       "      <td>0.369751</td>\n",
       "      <td>0.349000</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.425395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>6.271025</td>\n",
       "      <td>10.190634</td>\n",
       "      <td>0.904329</td>\n",
       "      <td>68.098228</td>\n",
       "      <td>0.843628</td>\n",
       "      <td>0.094649</td>\n",
       "      <td>0.880089</td>\n",
       "      <td>0.800858</td>\n",
       "      <td>0.311515</td>\n",
       "      <td>0.610723</td>\n",
       "      <td>0.665944</td>\n",
       "      <td>0.717996</td>\n",
       "      <td>2.215920</td>\n",
       "      <td>0.451833</td>\n",
       "      <td>0.433500</td>\n",
       "      <td>0.433104</td>\n",
       "      <td>0.508579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>8.018934</td>\n",
       "      <td>11.770276</td>\n",
       "      <td>0.987343</td>\n",
       "      <td>76.536362</td>\n",
       "      <td>0.985178</td>\n",
       "      <td>0.677773</td>\n",
       "      <td>0.983276</td>\n",
       "      <td>0.943621</td>\n",
       "      <td>0.704590</td>\n",
       "      <td>0.993604</td>\n",
       "      <td>1.540097</td>\n",
       "      <td>2.184725</td>\n",
       "      <td>3.527820</td>\n",
       "      <td>1.022769</td>\n",
       "      <td>0.648000</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.961435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year  Life Ladder  Log GDP per capita  Social support  \\\n",
       "count  1562.000000  1562.000000         1535.000000     1549.000000   \n",
       "mean   2011.820743     5.433676            9.220822        0.810669   \n",
       "std       3.419787     1.121017            1.184035        0.119370   \n",
       "min    2005.000000     2.661718            6.377396        0.290184   \n",
       "25%    2009.000000     4.606351            8.310665        0.748304   \n",
       "50%    2012.000000     5.332600            9.398610        0.833047   \n",
       "75%    2015.000000     6.271025           10.190634        0.904329   \n",
       "max    2017.000000     8.018934           11.770276        0.987343   \n",
       "\n",
       "       Healthy life expectancy at birth  Freedom to make life choices  \\\n",
       "count                       1553.000000                   1533.000000   \n",
       "mean                          62.249887                      0.728975   \n",
       "std                            7.960671                      0.145408   \n",
       "min                           37.766476                      0.257534   \n",
       "25%                           57.299580                      0.633754   \n",
       "50%                           63.803192                      0.748014   \n",
       "75%                           68.098228                      0.843628   \n",
       "max                           76.536362                      0.985178   \n",
       "\n",
       "        Generosity  Perceptions of corruption  Positive affect  \\\n",
       "count  1482.000000                1472.000000      1544.000000   \n",
       "mean      0.000079                   0.753622         0.708969   \n",
       "std       0.164202                   0.185538         0.107644   \n",
       "min      -0.322952                   0.035198         0.362498   \n",
       "25%      -0.114313                   0.697359         0.621471   \n",
       "50%      -0.022638                   0.808115         0.717398   \n",
       "75%       0.094649                   0.880089         0.800858   \n",
       "max       0.677773                   0.983276         0.943621   \n",
       "\n",
       "       Negative affect  Confidence in national government  Democratic Quality  \\\n",
       "count      1550.000000                        1401.000000         1391.000000   \n",
       "mean          0.263171                           0.480207           -0.126617   \n",
       "std           0.084006                           0.190724            0.873259   \n",
       "min           0.083426                           0.068769           -2.448228   \n",
       "25%           0.204116                           0.334732           -0.772010   \n",
       "50%           0.251798                           0.463137           -0.225939   \n",
       "75%           0.311515                           0.610723            0.665944   \n",
       "max           0.704590                           0.993604            1.540097   \n",
       "\n",
       "       Delivery Quality  Standard deviation of ladder by country-year  \\\n",
       "count       1391.000000                                   1562.000000   \n",
       "mean           0.004947                                      2.003501   \n",
       "std            0.981052                                      0.379684   \n",
       "min           -2.144974                                      0.863034   \n",
       "25%           -0.717463                                      1.737934   \n",
       "50%           -0.210142                                      1.960345   \n",
       "75%            0.717996                                      2.215920   \n",
       "max            2.184725                                      3.527820   \n",
       "\n",
       "       Standard deviation/Mean of ladder by country-year  \\\n",
       "count                                        1562.000000   \n",
       "mean                                            0.387271   \n",
       "std                                             0.119007   \n",
       "min                                             0.133908   \n",
       "25%                                             0.309722   \n",
       "50%                                             0.369751   \n",
       "75%                                             0.451833   \n",
       "max                                             1.022769   \n",
       "\n",
       "       GINI index (World Bank estimate)  \\\n",
       "count                        583.000000   \n",
       "mean                           0.372846   \n",
       "std                            0.086609   \n",
       "min                            0.241000   \n",
       "25%                            0.307000   \n",
       "50%                            0.349000   \n",
       "75%                            0.433500   \n",
       "max                            0.648000   \n",
       "\n",
       "       GINI index (World Bank estimate), average 2000-15  \\\n",
       "count                                        1386.000000   \n",
       "mean                                            0.386948   \n",
       "std                                             0.083694   \n",
       "min                                             0.228833   \n",
       "25%                                             0.321583   \n",
       "50%                                             0.371000   \n",
       "75%                                             0.433104   \n",
       "max                                             0.626000   \n",
       "\n",
       "       gini of household income reported in Gallup, by wp5-year  \n",
       "count                                        1205.000000         \n",
       "mean                                            0.445204         \n",
       "std                                             0.105410         \n",
       "min                                             0.223470         \n",
       "25%                                             0.368531         \n",
       "50%                                             0.425395         \n",
       "75%                                             0.508579         \n",
       "max                                             0.961435         "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#winsorize the data\n",
    "df['Confidence in national government']=stats.mstats.winsorize(df['Confidence in national government'], limits=[0.01, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                                                      object\n",
       "year                                                          int64\n",
       "Life Ladder                                                 float64\n",
       "Log GDP per capita                                          float64\n",
       "Social support                                              float64\n",
       "Healthy life expectancy at birth                            float64\n",
       "Freedom to make life choices                                float64\n",
       "Generosity                                                  float64\n",
       "Perceptions of corruption                                   float64\n",
       "Positive affect                                             float64\n",
       "Negative affect                                             float64\n",
       "Confidence in national government                           float64\n",
       "Democratic Quality                                          float64\n",
       "Delivery Quality                                            float64\n",
       "Standard deviation of ladder by country-year                float64\n",
       "Standard deviation/Mean of ladder by country-year           float64\n",
       "GINI index (World Bank estimate)                            float64\n",
       "GINI index (World Bank estimate), average 2000-15           float64\n",
       "gini of household income reported in Gallup, by wp5-year    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform one-hot encoding\n",
    "to_encode=list(df.select_dtypes(include=['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=OneHotEncoder(handle_unknown='error', sparse=False)\n",
    "df_enc=pd.DataFrame(encoder.fit_transform(df[to_encode]))\n",
    "df_enc.columns=encoder.get_feature_names(to_encode)\n",
    "df.drop(columns=df[to_encode], axis=1, inplace=True)\n",
    "df=df.join(df_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data\n",
    "for feature in df.columns:\n",
    "    df[feature]=(df[feature]-df[feature].min())/(df[feature].max()-df[feature].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Life Ladder</th>\n",
       "      <th>Log GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy at birth</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>Positive affect</th>\n",
       "      <th>Negative affect</th>\n",
       "      <th>...</th>\n",
       "      <th>country_United Arab Emirates</th>\n",
       "      <th>country_United Kingdom</th>\n",
       "      <th>country_United States</th>\n",
       "      <th>country_Uruguay</th>\n",
       "      <th>country_Uzbekistan</th>\n",
       "      <th>country_Venezuela</th>\n",
       "      <th>country_Vietnam</th>\n",
       "      <th>country_Yemen</th>\n",
       "      <th>country_Zambia</th>\n",
       "      <th>country_Zimbabwe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.198213</td>\n",
       "      <td>0.146729</td>\n",
       "      <td>0.230189</td>\n",
       "      <td>0.295157</td>\n",
       "      <td>0.632975</td>\n",
       "      <td>0.504406</td>\n",
       "      <td>0.892847</td>\n",
       "      <td>0.266965</td>\n",
       "      <td>0.281358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.324807</td>\n",
       "      <td>0.177344</td>\n",
       "      <td>0.375989</td>\n",
       "      <td>0.305855</td>\n",
       "      <td>0.579078</td>\n",
       "      <td>0.526185</td>\n",
       "      <td>0.859462</td>\n",
       "      <td>0.381035</td>\n",
       "      <td>0.247385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.391372</td>\n",
       "      <td>0.187142</td>\n",
       "      <td>0.357007</td>\n",
       "      <td>0.315773</td>\n",
       "      <td>0.470826</td>\n",
       "      <td>0.460249</td>\n",
       "      <td>0.708347</td>\n",
       "      <td>0.440127</td>\n",
       "      <td>0.308933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.218397</td>\n",
       "      <td>0.192406</td>\n",
       "      <td>0.331229</td>\n",
       "      <td>0.325016</td>\n",
       "      <td>0.327588</td>\n",
       "      <td>0.497920</td>\n",
       "      <td>0.734022</td>\n",
       "      <td>0.428291</td>\n",
       "      <td>0.295814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.209291</td>\n",
       "      <td>0.211340</td>\n",
       "      <td>0.330559</td>\n",
       "      <td>0.333836</td>\n",
       "      <td>0.375735</td>\n",
       "      <td>0.569698</td>\n",
       "      <td>0.780971</td>\n",
       "      <td>0.598646</td>\n",
       "      <td>0.297012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  Life Ladder  Log GDP per capita  Social support  \\\n",
       "0  0.250000     0.198213            0.146729        0.230189   \n",
       "1  0.333333     0.324807            0.177344        0.375989   \n",
       "2  0.416667     0.391372            0.187142        0.357007   \n",
       "3  0.500000     0.218397            0.192406        0.331229   \n",
       "4  0.583333     0.209291            0.211340        0.330559   \n",
       "\n",
       "   Healthy life expectancy at birth  Freedom to make life choices  Generosity  \\\n",
       "0                          0.295157                      0.632975    0.504406   \n",
       "1                          0.305855                      0.579078    0.526185   \n",
       "2                          0.315773                      0.470826    0.460249   \n",
       "3                          0.325016                      0.327588    0.497920   \n",
       "4                          0.333836                      0.375735    0.569698   \n",
       "\n",
       "   Perceptions of corruption  Positive affect  Negative affect  ...  \\\n",
       "0                   0.892847         0.266965         0.281358  ...   \n",
       "1                   0.859462         0.381035         0.247385  ...   \n",
       "2                   0.708347         0.440127         0.308933  ...   \n",
       "3                   0.734022         0.428291         0.295814  ...   \n",
       "4                   0.780971         0.598646         0.297012  ...   \n",
       "\n",
       "   country_United Arab Emirates  country_United Kingdom  \\\n",
       "0                           0.0                     0.0   \n",
       "1                           0.0                     0.0   \n",
       "2                           0.0                     0.0   \n",
       "3                           0.0                     0.0   \n",
       "4                           0.0                     0.0   \n",
       "\n",
       "   country_United States  country_Uruguay  country_Uzbekistan  \\\n",
       "0                    0.0              0.0                 0.0   \n",
       "1                    0.0              0.0                 0.0   \n",
       "2                    0.0              0.0                 0.0   \n",
       "3                    0.0              0.0                 0.0   \n",
       "4                    0.0              0.0                 0.0   \n",
       "\n",
       "   country_Venezuela  country_Vietnam  country_Yemen  country_Zambia  \\\n",
       "0                0.0              0.0            0.0             0.0   \n",
       "1                0.0              0.0            0.0             0.0   \n",
       "2                0.0              0.0            0.0             0.0   \n",
       "3                0.0              0.0            0.0             0.0   \n",
       "4                0.0              0.0            0.0             0.0   \n",
       "\n",
       "   country_Zimbabwe  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "\n",
       "[5 rows x 182 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Log GDP per capita', 'Social support', 'Healthy life expectancy at birth', 'Freedom to make life choices', 'Generosity', 'Perceptions of corruption', 'Positive affect', 'Negative affect', 'Confidence in national government', 'Democratic Quality', 'Delivery Quality', 'GINI index (World Bank estimate)', 'GINI index (World Bank estimate), average 2000-15', 'gini of household income reported in Gallup, by wp5-year']\n"
     ]
    }
   ],
   "source": [
    "#search for missing values\n",
    "nan_count=np.sum(df.isnull(), axis=0)\n",
    "condition=nan_count!=0\n",
    "col_names=nan_count[condition].index\n",
    "nan_cols=list(col_names)\n",
    "print(nan_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in missing values\n",
    "for column in df.columns:\n",
    "    df[column].fillna(value=df[column].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure missing values were replaced\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the features with the strongest correlation to the data\n",
    "exclude=['Confidence in national government']\n",
    "corrs=df.corr()['Confidence in national government'].drop(exclude, axis=0)\n",
    "corrs_sorted=corrs.sort_values(ascending=False)\n",
    "corrs_reverse=corrs.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_three_corr=list(corrs_sorted.index[0:3])\n",
    "neg_top_three_corr=list(corrs_reverse.index[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Freedom to make life choices', 'Generosity', 'country_Singapore', 'Perceptions of corruption', 'Healthy life expectancy at birth', 'Standard deviation of ladder by country-year']\n"
     ]
    }
   ],
   "source": [
    "#make a list of features that are strongly correlated to the label\n",
    "features=list(top_three_corr + neg_top_three_corr)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. You will:\n",
    "\n",
    "1. Prepare your data for your model and create features and a label.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "y=df['Confidence in national government']\n",
    "X=df.drop(columns='Confidence in national government', axis=1) \n",
    "#start with using all the columns as features, specialize later to hopefully prevent execution bottleneck and optimize performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.20, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin GBDT Implementation...\n",
      "Default GBDT Root Mean Squared Error : 0.1215410406002189\n",
      "Default GBDT R2 0.6320065432007932\n"
     ]
    }
   ],
   "source": [
    "print('Begin GBDT Implementation...') #building GBDT with default hyperparameters\n",
    "\n",
    "gbdt_model_default=GradientBoostingRegressor()\n",
    "#fit the model to the training data\n",
    "gbdt_model_default.fit(X_train, y_train)\n",
    "#make predictions on the test data\n",
    "y_gbdt_default_pred=gbdt_model_default.predict(X_test)\n",
    "#Compute the RMSE and R2 on y_test and y_gbdt_default_pred\n",
    "gbdt_default_rmse=mean_squared_error(y_test, y_gbdt_default_pred, squared=False)\n",
    "gbdt_default_r2=r2_score(y_test, y_gbdt_default_pred)\n",
    "\n",
    "print('Default GBDT Root Mean Squared Error : {0}'.format(gbdt_default_rmse))\n",
    "print('Default GBDT R2 {0}'.format(gbdt_default_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin RF Implementation...\n",
      "Default Random Forest Root Mean Squared Error: 0.1162949134420247\n",
      "Default Random Forest R2: 0.663088654930489\n"
     ]
    }
   ],
   "source": [
    "print('Begin RF Implementation...') #building RF with default hyperparameters\n",
    "\n",
    "rf_model_default=RandomForestRegressor()\n",
    "# Fit the model to the training data\n",
    "rf_model_default.fit(X_train, y_train)\n",
    "# Use the fitted model to make predictions on the test data. \n",
    "y_rf_default_pred=rf_model_default.predict(X_test)\n",
    "# Compute the RMSE and R2 (on y_test and y_rf_default_pred) \n",
    "rf_default_rmse=mean_squared_error(y_test, y_rf_default_pred, squared=False)\n",
    "rf_default_r2=r2_score(y_test, y_rf_default_pred)\n",
    "\n",
    "print('Default Random Forest Root Mean Squared Error: {0}'.format(rf_default_rmse))\n",
    "print('Default Random Forest R2: {0}'.format(rf_default_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin GBDT Implementation...\n",
      " Lab 6 GBDT Root Mean Squared Error : 0.11653791367823288\n",
      " Lab 6 GBDT R2 0.6616792197640702\n"
     ]
    }
   ],
   "source": [
    "print('Begin GBDT Implementation...') #building GBDT with hyperparameters from lab 6\n",
    "\n",
    "gbdt_model_lab=GradientBoostingRegressor(max_depth=2, n_estimators=300)\n",
    "#fit the model to the training data\n",
    "gbdt_model_lab.fit(X_train, y_train)\n",
    "#make a prediction on the test data\n",
    "y_gbdt_lab_pred=gbdt_model_lab.predict(X_test)\n",
    "#compute the RMSE and R2\n",
    "gbdt_lab_rmse=mean_squared_error(y_test, y_gbdt_lab_pred, squared=False)\n",
    "gbdt_lab_r2=r2_score(y_test, y_gbdt_lab_pred)\n",
    "\n",
    "print(' Lab 6 GBDT Root Mean Squared Error : {0}'.format(gbdt_lab_rmse))\n",
    "print(' Lab 6 GBDT R2 {0}'.format(gbdt_lab_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin RF Implementation...\n",
      "Lab 6 Random Forest Root Mean Squared Error: 0.11582913471936189\n",
      "Lab 6 Random Forest R2: 0.6657820122728492\n"
     ]
    }
   ],
   "source": [
    "print('Begin RF Implementation...') #building RF with hyperparameters from lab 6\n",
    "\n",
    "rf_model_lab=RandomForestRegressor(max_depth=32, n_estimators=300)\n",
    "# fit the model to the training data\n",
    "rf_model_lab.fit(X_train, y_train)\n",
    "# make predictions on the test data \n",
    "y_rf_lab_pred=rf_model_lab.predict(X_test)\n",
    "#compute the RMSE and R2 \n",
    "rf_lab_rmse=mean_squared_error(y_test, y_rf_lab_pred, squared=False)\n",
    "rf_lab_r2=r2_score(y_test, y_rf_lab_pred)\n",
    "\n",
    "print('Lab 6 Random Forest Root Mean Squared Error: {0}'.format(rf_lab_rmse))\n",
    "print('Lab 6 Random Forest R2: {0}'.format(rf_lab_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top six features: ['Perceptions of corruption', 'Freedom to make life choices', 'Healthy life expectancy at birth', 'Life Ladder', 'Log GDP per capita', 'Standard deviation of ladder by country-year']\n"
     ]
    }
   ],
   "source": [
    "#searching for the most influential features\n",
    "feature_imp=gbdt_model_default.feature_importances_\n",
    "\n",
    "dict1={'name': X_train.columns.values, 'imp': feature_imp}\n",
    "\n",
    "#convert dictionary to a dataframe\n",
    "df_best_features=pd.DataFrame(dict1)\n",
    "#sort the features, with the most influential at the beginning\n",
    "df_sorted=df_best_features.sort_values('imp', ascending=False)\n",
    "\n",
    "df_best_col=df_sorted['name']\n",
    "#create a list with the most important features\n",
    "top_six=list(df_best_col.iloc[:6])\n",
    "print('Top six features: {0}'.format(top_six))\n",
    "\n",
    "#feature2_imp=rf_model_default.feature_importances_\n",
    "#dict2={'name': X_train.columns.values, 'imp': feature2_imp}\n",
    "#df_best_features2=pd.DataFrame(dict1)\n",
    "#df_sorted2=df_best_features2.sort_values('imp', ascending=False)\n",
    "#df_col2=df_sorted2['name']\n",
    "#top_six=list(df_col2.iloc[:6])\n",
    "#print('Top six features: {0}'.format(top_six))\n",
    "\n",
    "#Performing feature selection with the random forest model produced the same results as the GBDT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': [2, 4, 8, 16, 32, 64],\n",
       " 'n_estimators': [25, 50, 100, 200, 400, 800]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performing a grid search to find the best hyperparameters for the GBDT\n",
    "\n",
    "md=[2**n for n in range(1, 7)]\n",
    "ne=[25*2**n for n in range(0, 6)]\n",
    "param_grid={'max_depth':md, 'n_estimators':ne}\n",
    "\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Grid Search...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Running Grid Search...') #grid search to find strong hyperparameters for the random forest\n",
    "\n",
    "model_rf=RandomForestRegressor()\n",
    "#run Grid Search with 5-fold cross-validation\n",
    "grid=GridSearchCV(model_rf, param_grid, cv=5)\n",
    "\n",
    "#fit the model to the training data\n",
    "grid_search_rf=grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value for max depth: 16\n",
      "Best value for number of estimators: 100\n"
     ]
    }
   ],
   "source": [
    "#access the best hyperparameter value for max_depth\n",
    "best_md_rf=grid_search_rf.best_estimator_.max_depth\n",
    "#access the best hyperparameter value for n_estimators\n",
    "best_ne_rf=grid_search_rf.best_estimator_.n_estimators\n",
    "\n",
    "print('Best value for max depth: {0}'.format(best_md_rf))\n",
    "print('Best value for number of estimators: {0}'.format(best_ne_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Grid Search...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Running Grid Search...') #grid search to find strong hyperparameters for the GBDT\n",
    "\n",
    "model_GBDT=GradientBoostingRegressor()\n",
    "#run Grid Search with 5-fold cross-validation\n",
    "grid=GridSearchCV(model_GBDT, param_grid, cv=5)\n",
    "\n",
    "#fit the model to the training data\n",
    "grid_search_GBDT=grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value for max depth: 4\n",
      "Best value for number of estimators: 800\n"
     ]
    }
   ],
   "source": [
    "#access the best hyperparameter value for max_depth\n",
    "best_md_GBDT=grid_search_GBDT.best_estimator_.max_depth\n",
    "#access the best hyperparameter value for n_estimators\n",
    "best_ne_GBDT=grid_search_GBDT.best_estimator_.n_estimators\n",
    "\n",
    "print('Best value for max depth: {0}'.format(best_md_GBDT))\n",
    "print('Best value for number of estimators: {0}'.format(best_ne_GBDT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin GBDT Implementation...\n",
      "End\n",
      "GBDT Best Hyperparameters Root Mean Squared Error : 0.10829456922133503\n",
      "GBDT Best Hyperparameters R2 0.7078488823023207\n"
     ]
    }
   ],
   "source": [
    "print('Begin GBDT Implementation...') #building GBDT with the best hyperparameters\n",
    "\n",
    "gbdt_model_hyp=GradientBoostingRegressor(max_depth=best_md_GBDT, n_estimators=best_ne_GBDT)\n",
    "#fit the model to the training data\n",
    "gbdt_model_hyp.fit(X_train, y_train)\n",
    "\n",
    "#make predictions on the test data\n",
    "y_gbdt_hyp_pred=gbdt_model_hyp.predict(X_test)\n",
    "\n",
    "#compute the RMSE and R2\n",
    "gbdt_hyp_rmse=mean_squared_error(y_test, y_gbdt_hyp_pred, squared=False)\n",
    "\n",
    "gbdt_hyp_r2=r2_score(y_test, y_gbdt_hyp_pred)\n",
    "\n",
    "print('End')\n",
    "\n",
    "print('GBDT Best Hyperparameters Root Mean Squared Error : {0}'.format(gbdt_hyp_rmse))\n",
    "print('GBDT Best Hyperparameters R2 {0}'.format(gbdt_hyp_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin RF Implementation...\n",
      "End\n",
      "Random Forest Best Hyperparameters Root Mean Squared Error: 0.11728122426231116\n",
      "Random Forest Best Hyperparameters R2 Score: 0.6573496517366115\n"
     ]
    }
   ],
   "source": [
    "print('Begin RF Implementation...') #building RF with the best hyperparameters\n",
    "\n",
    "rf_model_hyp=RandomForestRegressor(max_depth=best_md_rf, n_estimators=best_ne_rf)\n",
    "#fit the model to the training data\n",
    "rf_model_hyp.fit(X_train, y_train)\n",
    "\n",
    "#make predictions on the test data\n",
    "y_rf_hyp_pred=rf_model_hyp.predict(X_test)\n",
    "\n",
    "#compute the RMSE and R2 scores\n",
    "rf_hyp_rmse=mean_squared_error(y_test, y_rf_hyp_pred, squared=False)\n",
    "\n",
    "rf_hyp_r2=r2_score(y_test, y_rf_hyp_pred)\n",
    "\n",
    "print('End')\n",
    "\n",
    "print('Random Forest Best Hyperparameters Root Mean Squared Error: {0}'.format(rf_hyp_rmse))\n",
    "\n",
    "print('Random Forest Best Hyperparameters R2 Score: {0}'.format(rf_hyp_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_corr=df[features] #using strongly correlated features\n",
    "X_train_corr, X_test_corr, y_train, y_test=train_test_split(X_corr, y, test_size=0.20, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin GBDT Implementation...\n",
      "End\n",
      "GBDT With Strongly Correlated Features Root Mean Squared Error : 0.14450543470035734\n",
      "GBDT With Strongly Correlated Features R2 0.47980933121678004\n"
     ]
    }
   ],
   "source": [
    "print('Begin GBDT Implementation...') #building GBDT with the best hyperparameters and features that are strongly correlated to the label\n",
    "\n",
    "gbdt_model_corr=GradientBoostingRegressor(max_depth=best_md_GBDT, n_estimators=best_ne_GBDT)\n",
    "\n",
    "#fit the model to the training data\n",
    "gbdt_model_corr.fit(X_train_corr, y_train) #Here, the X_train_corr and X_test_corr feature sets are used\n",
    "\n",
    "#make predictions on the test data\n",
    "y_gbdt_corr_pred=gbdt_model_corr.predict(X_test_corr)\n",
    "\n",
    "#compute the RMSE and R2 scores\n",
    "gbdt_corr_rmse=mean_squared_error(y_test, y_gbdt_corr_pred, squared=False)\n",
    "\n",
    "gbdt_corr_r2=r2_score(y_test, y_gbdt_corr_pred)\n",
    "\n",
    "print('End')\n",
    "\n",
    "print('GBDT With Strongly Correlated Features Root Mean Squared Error : {0}'.format(gbdt_corr_rmse))\n",
    "print('GBDT With Strongly Correlated Features R2 {0}'.format(gbdt_corr_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin RF Implementation...\n",
      "End\n",
      "Random Forest Strongly Correlated Features Root Mean Squared Error: 0.12945060628316635\n",
      "Random Forest Strongly Correlated Features R2 Score: 0.582552010666106\n"
     ]
    }
   ],
   "source": [
    "print('Begin RF Implementation...') #building RF with the best hyperparameters and features that are strongly correlated to the label\n",
    "\n",
    "rf_model_corr=RandomForestRegressor(max_depth=best_md_rf, n_estimators=best_ne_rf)\n",
    "\n",
    "#fit the model to the training data\n",
    "rf_model_corr.fit(X_train_corr, y_train)\n",
    "\n",
    "#make predictions on the test data\n",
    "y_rf_corr_pred=rf_model_corr.predict(X_test_corr)\n",
    "\n",
    "#compute the RMSE and R2 scores\n",
    "rf_corr_rmse=mean_squared_error(y_test, y_rf_corr_pred, squared=False)\n",
    "\n",
    "rf_corr_r2=r2_score(y_test, y_rf_corr_pred)\n",
    "\n",
    "print('End')\n",
    "\n",
    "print('Random Forest Strongly Correlated Features Root Mean Squared Error: {0}'.format(rf_corr_rmse))\n",
    "\n",
    "print('Random Forest Strongly Correlated Features R2 Score: {0}'.format(rf_corr_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_best=df[top_six] #using best features\n",
    "X_train_best, X_test_best, y_train, y_test=train_test_split(X_best, y, test_size=0.20, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin GBDT Implementation...\n",
      "End\n",
      "GBDT With Best Features Root Mean Squared Error : 0.13525186026992897\n",
      "GBDT With Best Features R2 0.5442982563721321\n"
     ]
    }
   ],
   "source": [
    "print('Begin GBDT Implementation...') #building GBDT with the best hyperparameters and best features\n",
    "\n",
    "gbdt_model_best=GradientBoostingRegressor(max_depth=best_md_GBDT, n_estimators=best_ne_GBDT)\n",
    "\n",
    "#fit the model to the training data\n",
    "gbdt_model_best.fit(X_train_best, y_train) #Here, the X_train_best and X_test_best feature sets are used\n",
    "\n",
    "#make predictions on the test data\n",
    "y_gbdt_best_pred=gbdt_model_best.predict(X_test_best)\n",
    "\n",
    "#compute the RMSE and R2 scores\n",
    "gbdt_best_rmse=mean_squared_error(y_test, y_gbdt_best_pred, squared=False)\n",
    "\n",
    "gbdt_best_r2=r2_score(y_test, y_gbdt_best_pred)\n",
    "\n",
    "print('End')\n",
    "\n",
    "print('GBDT With Best Features Root Mean Squared Error : {0}'.format(gbdt_best_rmse))\n",
    "print('GBDT With Best Features R2 {0}'.format(gbdt_best_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin RF Implementation...\n",
      "End\n",
      "Random Forest Best Features Root Mean Squared Error: 0.13124155549820235\n",
      "Random Forest Best Features R2 Score: 0.5709213217358234\n"
     ]
    }
   ],
   "source": [
    "print('Begin RF Implementation...') #building RF with the best hyperparameters and best features\n",
    "\n",
    "rf_model_best=RandomForestRegressor(max_depth=best_md_rf, n_estimators=best_ne_rf)\n",
    "\n",
    "#fit the model to the training data\n",
    "rf_model_best.fit(X_train_best, y_train)\n",
    "\n",
    "#make predictions on the test data\n",
    "y_rf_best_pred=rf_model_best.predict(X_test_best)\n",
    "\n",
    "#compute the RMSE and R2 scores\n",
    "rf_best_rmse=mean_squared_error(y_test, y_rf_best_pred, squared=False)\n",
    "\n",
    "rf_best_r2=r2_score(y_test, y_rf_best_pred)\n",
    "\n",
    "print('End')\n",
    "\n",
    "print('Random Forest Best Features Root Mean Squared Error: {0}'.format(rf_best_rmse))\n",
    "\n",
    "print('Random Forest Best Features R2 Score: {0}'.format(rf_best_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create a bar graph to compare the results of each model\n",
    "RMSE_Results=[gbdt_default_rmse, rf_default_rmse, gbdt_lab_rmse, rf_lab_rmse, gbdt_hyp_rmse, rf_hyp_rmse, gbdt_corr_rmse, rf_corr_rmse, gbdt_best_rmse, rf_best_rmse]\n",
    "R2_Results=[gbdt_default_r2, rf_default_r2, gbdt_lab_r2, rf_lab_r2, gbdt_hyp_r2, rf_hyp_r2, gbdt_corr_r2, rf_corr_r2, gbdt_best_r2, rf_best_r2]\n",
    "labels=['D GB' , 'D RF', 'L GB',  'L RF', 'BH GB', 'BH RF', 'SC GB', 'SC RF', 'BF GB', 'BF RF ']\n",
    "\n",
    "#'D GB'= Default GBDT   'D RF'=Default Random Forest   'L GB'=Lab GBDT  'L RF'=Lab Random Forest\n",
    "#'BH GB'=Best Hyperparameters GBDT    'BH RF'=Best Hyperparameters Random Forest\n",
    "#'SC GB'=Strongly Correlated GBDT     'SC RF'=Strongly Correlated Random Forest\n",
    "#'BF GB'=Best Features GBDT           'BF RF'=Best Features Random Forest\n",
    "rg=np.arange(10)\n",
    "width=0.20\n",
    "\n",
    "plt.bar(rg, RMSE_Results, width, label=\"RMSE\")\n",
    "\n",
    "plt.bar(rg+width, R2_Results, width, label=\"R2\")\n",
    "\n",
    "plt.xticks(rg+width/2, labels)\n",
    "\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"RMSE and R2\")\n",
    "plt.ylim([0, 1])\n",
    "plt.title('Model Performance')\n",
    "plt.legend(loc='upper left', ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual model performance is quite different than what I predicted in my project plan. In order to reduce the chance of execution bottleneck, I thought it would be a good idea to only use the features that were strongly correlated to the label. However, this resulted in the weakest performance for both the gradient boosted decision tree (with an RMSE of 0.145 and R2 score of 0.480) and the second weakest for the random forest (with an RMSE of 0.130 and R2 score of 0.582). The performance of the GBDT using both the best hyperparameters and best features performed slightly better, having an RMSE of 0.135 and R2 score of 0.544. Interestingly enough, using these features resulted in the weakest random forest, with an RMSE of 0.131 and R2 score of 0.571. The best performance overall came from the GBDT which used all of the data frame's columns (except for the label) as features and the model's best hyperparameters, resulting in an RMSE of 0.108 and an R2 score of 0.708."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
